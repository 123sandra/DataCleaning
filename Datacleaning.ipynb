{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Email</th>\n",
       "      <th>Join Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1e407ff9-6255-489d-a0de-34135d4f74bd</td>\n",
       "      <td>Hunter Thomas</td>\n",
       "      <td>25.0</td>\n",
       "      <td>xlopez@hotmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88552.0</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>379f55b8-87d5-4739-a146-7400b78c24d1</td>\n",
       "      <td>Jeremy Irwin</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Jillian Jenkins</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>139227.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18261368-dfa1-47f0-afc6-bddf45926b07</td>\n",
       "      <td>Jennifer Hammondquickly</td>\n",
       "      <td>66.0</td>\n",
       "      <td>jscottgreen.biz</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>65550.0</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ae7cf7cf-17cf-4c8b-9c44-4f61a9a238e5</td>\n",
       "      <td>Sydney Taylorso</td>\n",
       "      <td>39.0</td>\n",
       "      <td>luke56gonzalez.com</td>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>139932.0</td>\n",
       "      <td>SupportJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14ed3e6a-e0f5-4bbe-8d93-8665267f5c90</td>\n",
       "      <td>Julia Lee</td>\n",
       "      <td>71.0</td>\n",
       "      <td>figueroakayla@yahoo.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143456.0</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    ID                     Name  \\\n",
       "0           0  1e407ff9-6255-489d-a0de-34135d4f74bd            Hunter Thomas   \n",
       "1           1  379f55b8-87d5-4739-a146-7400b78c24d1             Jeremy Irwin   \n",
       "2           2  18261368-dfa1-47f0-afc6-bddf45926b07  Jennifer Hammondquickly   \n",
       "3           3  ae7cf7cf-17cf-4c8b-9c44-4f61a9a238e5          Sydney Taylorso   \n",
       "4           4  14ed3e6a-e0f5-4bbe-8d93-8665267f5c90                Julia Lee   \n",
       "\n",
       "    Age                    Email   Join Date    Salary   Department  \n",
       "0  25.0       xlopez@hotmail.com         NaN   88552.0        Sales  \n",
       "1  90.0          Jillian Jenkins  2022-07-07  139227.0          NaN  \n",
       "2  66.0          jscottgreen.biz  2023-11-21   65550.0  Engineering  \n",
       "3  39.0       luke56gonzalez.com  2021-11-05  139932.0     SupportJ  \n",
       "4  71.0  figueroakayla@yahoo.com         NaN  143456.0    Marketing  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"messy_data.csv.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                    ID                     Name  \\\n",
       " 0           0  1e407ff9-6255-489d-a0de-34135d4f74bd            Hunter Thomas   \n",
       " 1           1  379f55b8-87d5-4739-a146-7400b78c24d1             Jeremy Irwin   \n",
       " 2           2  18261368-dfa1-47f0-afc6-bddf45926b07  Jennifer Hammondquickly   \n",
       " 3           3  ae7cf7cf-17cf-4c8b-9c44-4f61a9a238e5          Sydney Taylorso   \n",
       " 4           4  14ed3e6a-e0f5-4bbe-8d93-8665267f5c90                Julia Lee   \n",
       " \n",
       "     Age                    Email   Join Date    Salary   Department  \n",
       " 0  25.0       xlopez@hotmail.com         NaN   88552.0        Sales  \n",
       " 1  90.0          Jillian Jenkins  2022-07-07  139227.0          NaN  \n",
       " 2  66.0          jscottgreen.biz  2023-11-21   65550.0  Engineering  \n",
       " 3  39.0       luke56gonzalez.com  2021-11-05  139932.0     SupportJ  \n",
       " 4  71.0  figueroakayla@yahoo.com         NaN  143456.0    Marketing  ,\n",
       " Unnamed: 0       0\n",
       " ID               0\n",
       " Name          2333\n",
       " Age           1747\n",
       " Email         1269\n",
       " Join Date     2192\n",
       " Salary        2239\n",
       " Department    2255\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'messy_data.csv.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data_head = data.head()\n",
    "missing_values_summary = data.isnull().sum()\n",
    "\n",
    "data_head, missing_values_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                    ID                     Name  \\\n",
       " 0           0  1e407ff9-6255-489d-a0de-34135d4f74bd            Hunter Thomas   \n",
       " 1           1  379f55b8-87d5-4739-a146-7400b78c24d1             Jeremy Irwin   \n",
       " 2           2  18261368-dfa1-47f0-afc6-bddf45926b07  Jennifer Hammondquickly   \n",
       " 3           3  ae7cf7cf-17cf-4c8b-9c44-4f61a9a238e5          Sydney Taylorso   \n",
       " 4           4  14ed3e6a-e0f5-4bbe-8d93-8665267f5c90                Julia Lee   \n",
       " \n",
       "     Age                    Email   Join Date    Salary   Department  \n",
       " 0  25.0       xlopez@hotmail.com  2022-03-31   88552.0        Sales  \n",
       " 1  90.0          Jillian Jenkins  2022-07-07  139227.0      Support  \n",
       " 2  66.0          jscottgreen.biz  2023-11-21   65550.0  Engineering  \n",
       " 3  39.0       luke56gonzalez.com  2021-11-05  139932.0     SupportJ  \n",
       " 4  71.0  figueroakayla@yahoo.com  2022-03-31  143456.0    Marketing  ,\n",
       " Unnamed: 0    0\n",
       " ID            0\n",
       " Name          0\n",
       " Age           0\n",
       " Email         0\n",
       " Join Date     0\n",
       " Salary        0\n",
       " Department    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = len(data) * 0.5\n",
    "columns_to_drop = [col for col in data.columns if data[col].isnull().sum() > threshold]\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "numerical_cols = data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "data_cleaned[numerical_cols] = data_cleaned[numerical_cols].fillna(data_cleaned[numerical_cols].mean())\n",
    "categorical_cols = data_cleaned.select_dtypes(include=['object']).columns\n",
    "data_cleaned[categorical_cols] = data_cleaned[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "missing_values_summary_cleaned = data_cleaned.isnull().sum()\n",
    "\n",
    "data_cleaned.head(), missing_values_summary_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Unnamed: 0                                    ID  \\\n",
       " 0              0  1e407ff9-6255-489d-a0de-34135d4f74bd   \n",
       " 1              1  379f55b8-87d5-4739-a146-7400b78c24d1   \n",
       " 2              2  18261368-dfa1-47f0-afc6-bddf45926b07   \n",
       " 3              3  ae7cf7cf-17cf-4c8b-9c44-4f61a9a238e5   \n",
       " 4              4  14ed3e6a-e0f5-4bbe-8d93-8665267f5c90   \n",
       " ...          ...                                   ...   \n",
       " 7102        7102  784f6cca-d9ae-4891-913b-6558325cb669   \n",
       " 7103        7103  897338dc-46ec-4a25-b505-314eeaa9035d   \n",
       " 7104        7104  9c1bb0a9-1097-41ca-a55b-21d18ab671f0   \n",
       " 7105        7105  70a75065-2225-4c1f-a03f-ed266041f082   \n",
       " 7106        7106  68ac5636-1732-47c1-aff9-273db7bbf36b   \n",
       " \n",
       "                          Name       Age                    Email   Join Date  \\\n",
       " 0               Hunter Thomas  25.00000       xlopez@hotmail.com  2022-03-31   \n",
       " 1                Jeremy Irwin  90.00000          Jillian Jenkins  2022-07-07   \n",
       " 2     Jennifer Hammondquickly  66.00000          jscottgreen.biz  2023-11-21   \n",
       " 3             Sydney Taylorso  39.00000       luke56gonzalez.com  2021-11-05   \n",
       " 4                   Julia Lee  71.00000  figueroakayla@yahoo.com  2022-03-31   \n",
       " ...                       ...       ...                      ...         ...   \n",
       " 7102              Tanya Burch  54.16265   jasonmartinezgmail.com  2022-05-19   \n",
       " 7103       Elizabeth Williams  54.16265      fwilliams@yahoo.com  2022-03-31   \n",
       " 7104          Jeffery Shepard  25.00000       adrienne82@cox.com  2023-05-20   \n",
       " 7105            Richard Brown  23.00000      hhamilton@gmail.com  10/08/1982   \n",
       " 7106        Jonathan Anderson  47.00000      gthomas@hotmail.com  2023-03-31   \n",
       " \n",
       "              Salary   Department  \n",
       " 0      88552.000000        Sales  \n",
       " 1     139227.000000      Support  \n",
       " 2      65550.000000  Engineering  \n",
       " 3     139932.000000     SupportJ  \n",
       " 4     143456.000000    Marketing  \n",
       " ...             ...          ...  \n",
       " 7102  154923.514148      Support  \n",
       " 7103   89886.585012      Support  \n",
       " 7104  114636.000000  Engineering  \n",
       " 7105   36527.435177       Salesx  \n",
       " 7106   86842.000000      Support  \n",
       " \n",
       " [7107 rows x 8 columns],\n",
       " 'cleaned_dataset.csv')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned_sample = data_cleaned.head(7107)\n",
    "\n",
    "cleaned_file_path = 'cleaned_dataset.csv'\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "data_cleaned_sample, cleaned_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows removed: 291\n",
      "Unique dataset saved to: cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "data_unique = data_cleaned.drop_duplicates()\n",
    "duplicates_removed = len(data_cleaned) - len(data_unique)\n",
    "print(f\"Number of duplicate rows removed: {duplicates_removed}\")\n",
    "\n",
    "unique_file_path = 'cleaned_dataset.csv'\n",
    "data_unique.to_csv(unique_file_path, index=False)\n",
    "\n",
    "print(f\"Unique dataset saved to: {unique_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with professional email addresses saved to: cleanedd_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data_unique = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "def is_valid_email(email):\n",
    "    regex = r'^\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    return re.match(regex, email) is not None\n",
    "\n",
    "def correct_email_format(email):\n",
    "    if not is_valid_email(email):\n",
    "        return None  \n",
    "    return email\n",
    "\n",
    "data_unique['Email'] = data_unique['Email'].apply(correct_email_format)\n",
    "professional_domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com']\n",
    "\n",
    "def is_professional_email(email):\n",
    "    if email:\n",
    "        domain = email.split('@')[-1]\n",
    "        return domain in professional_domains\n",
    "    return False\n",
    "\n",
    "data_professional_emails = data_unique[data_unique['Email'].apply(is_professional_email)]\n",
    "\n",
    "professional_emails_file_path = 'cleanedd_dataset.csv'\n",
    "data_professional_emails.to_csv(professional_emails_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset with professional email addresses saved to: {professional_emails_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with cleaned names saved to: cleanedd_datase.csv\n"
     ]
    }
   ],
   "source": [
    "data_professional_emails = pd.read_csv('cleanedd_dataset.csv')\n",
    "\n",
    "def clean_name(name):\n",
    "    clean_name = re.sub(r'[^a-zA-Z\\s]', '', name).strip()\n",
    "    clean_name = ' '.join([part.capitalize() for part in clean_name.split()])\n",
    "    return clean_name\n",
    "\n",
    "data_professional_emails['Name'] = data_professional_emails['Name'].apply(clean_name)\n",
    "cleaned_names_file_path = 'cleanedd_datase.csv'\n",
    "data_professional_emails.to_csv(cleaned_names_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset with cleaned names saved to: {cleaned_names_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with standardized dates saved to: cleanedd_datasett.csv\n"
     ]
    }
   ],
   "source": [
    "data_cleaned_names = pd.read_csv('cleanedd_dataset.csv')\n",
    "\n",
    "def standardize_date(date_str):\n",
    "    try:\n",
    "        standardized_date = pd.to_datetime(date_str, errors='coerce').strftime('%Y-%m-%d')\n",
    "    except Exception:\n",
    "        standardized_date = None\n",
    "    return standardized_date\n",
    "data_cleaned_names['Join Date'] = data_cleaned_names['Join Date'].apply(standardize_date)\n",
    "standardized_dates_file_path = 'cleanedd_datasett.csv'\n",
    "data_cleaned_names.to_csv(standardized_dates_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset with standardized dates saved to: {standardized_dates_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with standardized department names saved to: leanedd_datasett.csv\n"
     ]
    }
   ],
   "source": [
    "data_standardized_dates = pd.read_csv('cleanedd_datasett.csv')\n",
    "\n",
    "department_mapping = {\n",
    "    'HR': 'HR',\n",
    "    'HRs': 'HR',\n",
    "    'Engineering': 'Engineering',\n",
    "    'Engineeringm': 'Engineering',\n",
    "    'Marketing': 'Marketing',\n",
    "    'Sales': 'Sales',\n",
    "    'SalesE': 'Sales',\n",
    "    'SalesY': 'Sales',\n",
    "    'Salest': 'Sales',\n",
    "    'SalesD': 'Sales',\n",
    "    'Support': 'Support',\n",
    "    'Enginering': 'Engineering',\n",
    "    'Mktg': 'Marketing',\n",
    "    'Marketinge': 'marketing',\n",
    "    'MarketingR': 'Marketing',\n",
    "    'Slaes': 'Sales',\n",
    "    'SalesM': 'Sales',\n",
    "    'Suport': 'Support',\n",
    "    'SupportJ': 'Support',\n",
    "    'SupportE': 'Support',\n",
    "    'SupportF': 'Support',\n",
    "}\n",
    "\n",
    "def correct_department(dept):\n",
    "    return department_mapping.get(dept, dept)\n",
    "\n",
    "data_standardized_dates['Department'] = data_standardized_dates['Department'].apply(correct_department)\n",
    "standardized_departments_file_path = 'leanedd_datasett.csv'\n",
    "data_standardized_dates.to_csv(standardized_departments_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset with standardized department names saved to: {standardized_departments_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with cleaned salary values saved to: cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "data_standardized_departments = pd.read_csv('leanedd_datasett.csv')\n",
    "\n",
    "data_standardized_departments['Salary'] = pd.to_numeric(data_standardized_departments['Salary'], errors='coerce')\n",
    "min_salary = 30000\n",
    "max_salary = 200000\n",
    "\n",
    "data_standardized_departments = data_standardized_departments[(data_standardized_departments['Salary'] >= min_salary) & \n",
    "                                                              (data_standardized_departments['Salary'] <= max_salary)]\n",
    "mean_salary = data_standardized_departments['Salary'].mean()\n",
    "data_standardized_departments['Salary'].fillna(mean_salary, inplace=True)\n",
    "\n",
    "cleaned_salary_file_path = 'cleaned_dataset.csv'\n",
    "data_standardized_departments.to_csv(cleaned_salary_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset with cleaned salary values saved to: {cleaned_salary_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
